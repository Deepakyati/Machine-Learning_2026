{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "267d43c6",
   "metadata": {},
   "source": [
    "Machine Learning day1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c3ce0",
   "metadata": {},
   "source": [
    "Types of ML\n",
    "- Supervised learning: (input and output variable given to train the model, so that we can predict)\n",
    "- ex.\n",
    "- \n",
    "- Unsupervised learning: (here also we will get the data, but we are not going to predict anything)\n",
    "- ex. find patterns, group similar items, reduce complexity, spot outliers\n",
    "- \n",
    "- Reinforcement Learning: (learning by trial and error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c3151b",
   "metadata": {},
   "source": [
    "Supervised learning Algorithms\n",
    "- Linear regression\n",
    "- Logistic regression\n",
    "- \n",
    "-\n",
    "-\n",
    "-\n",
    "-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34411b46",
   "metadata": {},
   "source": [
    "EDA\n",
    "\n",
    "Steps involved in making Machine Learning Model\n",
    "\n",
    "- 1. Problem definition\n",
    "- 2. Data collection\n",
    "- 3. Exploratory data analysis(EDA)\n",
    "- 4. Data Preprocessing/cleaning\n",
    "- 5. Feature selection and engineering\n",
    "- 6. Split the dataset\n",
    "- 7. Model selection\n",
    "- 8. Model Training\n",
    "- 9. Model evaluation\n",
    "- 10. Hyperparameter tuning\n",
    "- 11. Model testing/validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7abce4a",
   "metadata": {},
   "source": [
    "Exploratory data analysis:\n",
    "\n",
    "step where you explore the data\n",
    "1. Understand the data\n",
    "2. Discover pattern\n",
    "3. Spot anomalies\n",
    "4. generate insights\n",
    "5. And decide what to do next\n",
    "\n",
    "\n",
    "\n",
    "EDA Steps\n",
    "1) Viewing the data\n",
    "- head(), tail(), shape, infor()\n",
    "- what coloumn do i have\n",
    "- what type of data i have?\n",
    "\n",
    "2) Summary Statistics\n",
    "- mean, median, mode, std, min, max, quartiles\n",
    "- helps understand spread and central tendency\n",
    "\n",
    "3) Value counts\n",
    "- how many qunique values in a coloumn?\n",
    "- Greate for categorical columns\n",
    "\n",
    "4) Missing value analysis\n",
    "- Where are the gaps?\n",
    "- what % of data is missing ?\n",
    "\n",
    "5) Visualizations\n",
    "- Histograms -> distribution of values\n",
    "- Boxplots -> outliers and spread\n",
    "- Bar plots -> comparisons of categories\n",
    "- Correlation heatmaps -> linear relationship between numerical features\n",
    "- Scatter plots ->bivariate relationship\n",
    "\n",
    "6) Target variable exploration\n",
    "- How does your output related to other variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eddb90",
   "metadata": {},
   "source": [
    "Data cleaning\n",
    "\n",
    "1. Handling missing values\n",
    "- check which coloumns have missing values?\n",
    "\n",
    "- Strategies to handle:\n",
    "- drop missing rows/coloumns\n",
    "- impute with:\n",
    "  - Mean/Median -> for numerical data\n",
    "  - Mode ->for categorical data\n",
    "  - Advanced: Linear regression, KNN\n",
    "\n",
    "\n",
    "\n",
    "2. Remove Duplicates\n",
    "  - detect and drop exact duplicate rows\n",
    "\n",
    "3. Fix data types\n",
    "  - Convert wrong types (ex. number stored as string, date as text)\n",
    "\n",
    "4. Handle inconsistent categories\n",
    "  - cleanup up categorical values (ex. male, Male, MALE -> should become male)\n",
    "\n",
    "5. Detect and handle outliers\n",
    "  - Use boxplots, IQR or Zscore\n",
    "  - handle by:\n",
    "    - removing\n",
    "    - capping\n",
    "\n",
    "6. Fix Logic or Domain errors\n",
    " - \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ab8fe3",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "\n",
    "To prepare clean data so it can be used in a aML model\n",
    "\n",
    "If data cleaning is about fixing mistakes,\n",
    "\n",
    "Data preprocessing is about transforming valid data into a usable format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786536fb",
   "metadata": {},
   "source": [
    "1. Encoding categorical variables\n",
    " - convert text labels into numbers (ex. Yes and No -> 1 and 0)\n",
    "\n",
    "- Two common methods\n",
    "  - Label Encoding (Ordinal): good for categorical\n",
    "  - One-Hot Encoding (Nominal)\n",
    "\n",
    "\n",
    "2. Feature Transformation\n",
    "- used to handle skewed data like right-skewed data or left-skewed data\n",
    "\n",
    "3. Feature Scaling (Normalization or Standardization)\n",
    "- Bring numerical value to the same scale - especially for distance-based algorithms\n",
    "\n",
    "   - Normalization (Min Max scaling), scales value between 0 & 1\n",
    "   - Standardization (Z-score Scaling), transform data to have mean 0 and std 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34239f3",
   "metadata": {},
   "source": [
    "Feature Engineering\n",
    "- creating new features or transforming existing ones to expose useful patterns that ML model can learn from\n",
    "- common techniques\n",
    " - Mathematical combinations\n",
    " - Target based flags\n",
    " - Binning (when it helps)\n",
    " - time based features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f092fdd1",
   "metadata": {},
   "source": [
    "Feature Selection \n",
    "\n",
    "- Selecting the most useful features and removing the rest\n",
    "\n",
    "Why is it importance?\n",
    "  - Reduce noise and overfitting\n",
    "  - Speeds up training\n",
    "  - Improves model accuracy\n",
    "  - Make model interpretation easier\n",
    "\n",
    "\n",
    "1. Filter Methods(Pure Statistics)\n",
    "  - Correlation matrix -> remove highly correlated features\n",
    "  - Chi-squared test(categorical vs categorical)\n",
    "  - ANOVA F-test (numerical vs categorical target)\n",
    "\n",
    "2. Embedded Methods(selection built into the model)\n",
    "  - Lasso regression ->Shrinks coefficients to 0\n",
    "  - Tree-based models(random Forest, XGBoost) ->Feature importance scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
